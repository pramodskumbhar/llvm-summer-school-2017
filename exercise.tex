\documentclass[12pt]{article}
\usepackage{minted}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage[trim]{tokenizer}

\makeatletter

\newcounter{sncolumncounter}
\newcounter{snrowcounter}

\def \nodelabel#1{%
\setcounter{snrowcounter}{1}
 \foreach \i in {#1}{%
   \draw (\value{sncolumncounter},\value{snrowcounter}) node[anchor=south]{\i};
   \addtocounter{snrowcounter}{1}
 }
 \addtocounter{sncolumncounter}{1}
}

\def \nodeconnection#1{%
  \foreach \i in {#1}{%
    \GetTokens{nodesrc}{nodedest}{\i}
    \draw (\value{sncolumncounter},\nodesrc) node[circle,fill=black]{}--(\value{sncolumncounter},\nodedest) node[circle,fill=black]{};
  }
  \addtocounter{sncolumncounter}{1}
}

\newenvironment{sortingnetwork}[3]
{
  \setcounter{sncolumncounter}{0}
  \def \sn@fullsize{15}
  \begin{tikzpicture}[scale=#3*\sn@fullsize/#2]
  \foreach \i in {1, ..., #1}
  {
    \draw (0,\i)--(#2-1,\i);
  }
}
{
  \end{tikzpicture}
}
\makeatother


\begin{document}

{
\centering
\Huge{
Exercise\\
Parallel Code with LLVM\\
SIMDization\\
}}

\section {Use C/C++ extensions to write vector code}

This exercise explores the LLVM vector instruction set by manually writing
vector code using the gcc and clang vector extensions for C and C++. The
primary goal of this exercise is to understand how to quickly generate vector
IR from C code to serve as reference for LLVM-IR optimization that will be
developed later.

\subsection{Vector Addition}
We begin with a simple scalar loop program, vector addition:

\begin{minted}{c}
#define N (1024 * 1024 * 1024)

void vector_addition(float *A, float *B) {
  // We assume that N is a multiple of 4.
  for (long i = 0; i < N/4; i++)
    A[i] += B[i];
}
\end{minted}

\begin{enumerate}
	\item Translate the scalar program into LLVM-IR using the command:\\
	      \texttt{clang -S -emit-llvm -O3 -fno-vectorize vector-addition.c -o vector-addition.ll}
	\item Use the generic C/C++ vector extensions to vectorize the IR.
	\item Generate LLVM-IR for your vectorized code using again the command:
	      \texttt{clang -S -emit-llvm -O3 vector-addition.simd.c -o vector-addition.simd.ll }
	\item Generate assembly code for both examples and compare the output.
	\item Generate binaries and compare their performance.
	\item Compile the scalar program without \texttt{-fno-vectorize} and
              compare generated LLVM-IR, assembly, and performance with the
              manually optimized program.
	\item Use \texttt{-Rpass=loop-vectorize} to verify that the scalar loop
	      has been automatically vectorized and use
              \texttt{-Rpass-missed=loop-vectorize} to verify that the manually
              vectorized loop has not been vectorized automatically.
	\item Instead of just adding a vector B, add a vector B0, B1, B2, ...,
	      B9. Try first with B0 - B5 and then with B0 - B9. Check again for
	      each configuration if the loop is vectorized. Understand the
	      reason why the loop is not vectorized and provide the relevant
	      information to get it vectorized automatically. How is the
	      additional information that you provided represented in LLVM-IR?
\end{enumerate}

\subsection{Sorting Networks}

To sort a small set of numbers efficiently in registers, sorting networks can
be used. Sorting networks sort a set of N input elements by repeatedly
performing pairwise \texttt{swaps}, where the swap operation ensures that the
corresponding element pair is sorted (e.g., using $<=$).

~\\
\textbf{Sorting network: Batcher's Merge-Exchange for N=4}\\

\begin{sortingnetwork}{4}{5}{0.5}
\nodelabel{0, 1, 2, 3}
\nodeconnection{{0+1,2+1}}
\nodeconnection{{1+1,3+1}}
\nodeconnection{{0+1,1+1}, {2+1,3+1}}
\nodeconnection{{1+1,2+1}}
\end{sortingnetwork}

~\\
This sorting network uses 5 comparators grouped into 3 parallel operations:\\

\begin{tabular}{l|l}
(0, 2) & (1, 3)\\
\hline
(0, 1) & (2, 3)\\
\hline
(1, 2) & \\
\end{tabular}

\begin{enumerate}
\item Use C/C++ vector extensions to implement the sorting network above.
\item Analyze the IR generated by:\\ \texttt{clang -O3 -std=c++1z -march=corei7-avx sorting-network.cpp -S -emit-llvm}
\item Analyze the assembly code generated by:\\ \texttt{clang -O3 -std=c++1z -march=corei7-avx sorting-network.cpp -S}
\end{enumerate}


Help:
\begin{itemize}
	\item C/C++ vector extensions: \url{https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors}
	\item \texttt{\_\_builtin\_shufflevector}: \url{https://clang.llvm.org/docs/LanguageExtensions.html#langext-builtin-shufflevector}
	\item The \texttt{swap} operation can be implemented with element-wise
              min and max operations. Use for these the following intrinsics:
\begin{minted}{c}
double4 min(double4 A, double4 B) {                                              
  return __builtin_ia32_minpd256(A, B);                                          
}                                                                                
                                                                                 
double4 max(double4 A, double4 B) {                                              
  return __builtin_ia32_maxpd256(A, B);                                          
}                                                                                
                                                                                 
double2 min(double2 A, double2 B) {                                              
  return __builtin_ia32_minpd(A, B);                                             
}                                                                                
                                                                                 
double2 max(double2 A, double2 B) {                                              
  return __builtin_ia32_maxpd(A, B);                                             
}       
\end{minted}
\end{itemize}


~\\
~\\
\textbf{Bonus: Batcher's Merge-Exchange for N=8}

\begin{sortingnetwork}{8}{13}{0.8}
\nodelabel{0, 1, 2, 3, 4, 5, 6, 7}
\nodeconnection{{0+1,4+1}}
\nodeconnection{{1+1,5+1}}
\nodeconnection{{2+1,6+1}}
\nodeconnection{{3+1,7+1}}
\nodeconnection{{0+1,2+1}, {4+1,6+1}}
\nodeconnection{{1+1,3+1}, {5+1,7+1}}
\nodeconnection{{2+1,4+1}, {0+1,1+1},{6+1,7+1}}
\nodeconnection{{3+1,5+1}}
\nodeconnection{{2+1,3+1},{4+1,5+1}}
\nodeconnection{{1+1,4+1}}
\nodeconnection{{3+1,6+1}}
\nodeconnection{{1+1,2+1},{3+1,4+1},{5+1,6+1}}
\end{sortingnetwork}

~\\
~\\
This sorting network uses 5 comparators grouped into 6 parallel operations:\\

\begin{tabular}{l|l|l|l}
(0,4)&(1,5)&(2,6)&(3,7)\\
(0,2)&(1,3)&(4,6)&(5,7)\\
(2,4)&(3,5)&(0,1)&(6,7)\\
(2,3)&(4,5)\\
(1,4)&(3,6)\\
(1,2)&(3,4)&(5,6)\\
\end{tabular}

~\\
~\\

\section{A simple loop vectorizer}

Write a simple loop vectorizer that is capable of vectorizing the following
code automatically:

\begin{minted}{c}
void vector_addition(float *A, float *B) {
  for (long i = 0; i < 1024; i++)
    A[i] += B[i];
}
\end{minted}

The goal of this exercise is to learn about canonicalizations which LLVM
passes and analysis expect, to understand how to use LoopInfo and
ScalarEvolution, and to understand how to analyse the LLVM-IR.


\begin{enumerate}
	\item Translate your example to LLVM-IR and canonicalize the IR:\\
              \texttt{-mem2reg -instnamer -loop-rotate}.
	\item Write a simple pass that lists all innermost loops, the basic
              blocks they contain, as well as the number of times each loop
              is executed (use scalar evolution for the latter).
	\item Compute for each memory access the stride (distance) with which
              subsequent loop iterations of the same load/store instruction
              access memory.
	\item Extend this pass to only match loops that are canonical. A loop
              is (very) canonical if:
	\begin{itemize}
		\item The loop is in loop simplify form
		\item Scalar evolution can compute the backedge taken count
		\item Only two basic blocks: a loop latch (backedge) and a loop
header exist
		\item All instructions but the induction variable increment and
		      the exit comparison are in the loop header (and are
		      consequently executed before the loop is exited in a
                      given iteration).
		\item The induction variable starts at zero, is incremented by
                      one and is compared against the upper loop bound by using
                      a signed-less-than comparison..
		\item All memory accesses are stride one.
		\item The body only contains load, store, fadd, and
                      getelementptr instructions.
		\item The number of loop iterations is a multiple of the
                      vectorization factor (e.g., 4)
	\end{itemize}
	\item Adjust the loop to increment in strides of the vector factor and
              replicate each instruction 'vector-factor' times. Use a local
              map to update the operands of each instruction to access the
              right version of each instruction.
	\item Vectorize: use a vector load whenever you encounter a stride-one
	      load, use a vector add whenever both operands are already
	      available as vector values, and use a vector store whenever
              the load to be stored is available as vector value and the store
              is stride one.
	\item Run your code on the above test case and show that the output
              is vectorized.
\end{enumerate}

~\\
~\\

\textbf{Bonus}
\begin{enumerate}
	\item Support stride-zero and stride-X (scatter, gather) loads and
              stores.
	\item Support mixed vector and non-vector code.
	\item Add a simple cost model using TargetTransformInfo
	\item Collect the minimal and maximal memory access offsets using
              Scalar Evolution and derive run-time alias checks for your
              arrays.
\end{enumerate}
\end{document} 
